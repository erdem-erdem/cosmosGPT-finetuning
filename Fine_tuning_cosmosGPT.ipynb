{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha-GiEat0_XF"
      },
      "source": [
        "# **Let's fine-tune cosmosGPT on ... dataset**\n",
        "\n",
        "CosmosGPT is a GPT-2 based 774 million parameter model, so it'll be quite fast. (quite fast... hehe)\n",
        "\n",
        "To show how fine-tuning affects a model, same instruction will be answered before and after fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPFMIVC00_dh",
        "outputId": "4a4816ce-00b4-4095-abeb-5348ac65b681"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.36.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.25.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2023.11.17)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.28.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (1.25.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in c:\\users\\yusuf\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (5.9.6)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (0.23.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (2023.12.2)\n",
            "Requirement already satisfied: requests in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KkQy6R4O2zx8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\yusuf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "c:\\Users\\yusuf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "c:\\Users\\yusuf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\yusuf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, GPT2LMHeadModel\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVR1c9ax20gi",
        "outputId": "3f62b9dd-a7f8-4f42-df44-760a8402c2ac"
      },
      "outputs": [],
      "source": [
        "#model = GPT2LMHeadModel.from_pretrained(\"ytu-ce-cosmos/turkish-gpt2\")\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"ytu-ce-cosmos/turkish-gpt2\")\n",
        "\n",
        "# Use these lines to pull the model from Huggingface."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "#model.save_pretrained(\"MYcosmosGPT\")\n",
        "#tokenizer.save_pretrained(\"MYcosmosGPT\")\n",
        "\n",
        "# Use these lines to save the loaded model locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = GPT2LMHeadModel.from_pretrained(\"./MycosmosGPT\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./MycosmosGPT\")\n",
        "\n",
        "# Use these lines to load a locally saved model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5ELBHU6p8NBI"
      },
      "outputs": [],
      "source": [
        "if tokenizer.pad_token is None:\n",
        "  tokenizer.pad_token = tokenizer.eos_token\n",
        "  tokenizer.pad_token_id = tokenizer.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69U7Xvx9-I5L",
        "outputId": "6ea4009b-c2b3-4862-ad95-c1dbe84fcb7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[18486, 23877,  2106,  5677, 29186,   373,   743,   843,   915,  3624,\n",
              "            14,   603, 50174,   277,  7993,   717,   199, 18486, 23877,  2106,\n",
              "          5677, 29186,   373,   743,   843,   915,  3624,    14,   199, 18486,\n",
              "          6310, 22447,    14,   517,  1010,  8297, 11112,   417,   373,  3064,\n",
              "         32522,    31,   199, 18486,  6310, 22447,    14,   517,  1010,  8297,\n",
              "         11112,   417,   373,  3064, 32522,    31,   199, 18486,  6310, 22447,\n",
              "            14,   517,  1010,  8297, 11112,   417,   373,  3064, 32522,    31,\n",
              "           199, 18486,  6310, 22447,    14,   517,  1010,  8297, 11112,   417,\n",
              "           373,  3064, 32522,    31,   199, 18486,  6310, 22447,    14,   517,\n",
              "          1010,  8297, 11112,   417,   373,  3064, 32522,    31,   199, 18486]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Workflow of generating: Choose prompt, encode it, feed it to the model, decode the output.\n",
        "\n",
        "prompt = \"Zor günlere rağmen hayatı sevmek için 5 neden sırala.\"\n",
        "\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "output = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        "    max_length=100\n",
        ")\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvxCcloyJuvm",
        "outputId": "724f2aea-9bd6-4175-8034-ea471a996933"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvPJibvnKmo6",
        "outputId": "a8e336bf-36bd-4ef9-bf9c-0a1b5cda8b6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zor günlere rağmen hayatı sevmek için 5 neden sırala. - KizlarSoruyor\n",
            "Zor günlere rağmen hayatı sevmek için 5 neden sırala.\n",
            "Zor günler geçirdik. Bu zor günleri atlatmak için neler yapmalıyız?\n",
            "Zor günler geçirdik. Bu zor günleri atlatmak için neler yapmalıyız?\n",
            "Zor günler geçirdik. Bu zor günleri atlatmak için neler yapmalıyız?\n",
            "Zor günler geçirdik. Bu zor günleri atlatmak için neler yapmalıyız?\n",
            "Zor günler geçirdik. Bu zor günleri atlatmak için neler yapmalıyız?\n",
            "Zor\n"
          ]
        }
      ],
      "source": [
        "text = tokenizer.decode(output[0], skip_special_tokens=False)\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9h4F0rcMpIk"
      },
      "source": [
        "## Now let's fine-tune the model and generate outputs for the same instruction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6VV39R4M-UM",
        "outputId": "4e23afd8-bb68-4f39-c8e4-34d3acb205e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Skipping huggingace_hub as it is not installed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.23.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (3.12.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (2023.12.2)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: requests in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (4.9.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub) (2023.11.17)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.19.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (1.25.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.1.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2023.12.2)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.23.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: colorama in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\yusuf\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall huggingace_hub\n",
        "!pip install huggingface_hub\n",
        "\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fgygQDQGMvQC"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "from datasets import load_dataset\n",
        "from datasets import Dataset as Ds\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "B3Zd7-uYM4ZV"
      },
      "outputs": [],
      "source": [
        "ds_len = 2000       #You can experiment with less training to see the result.\n",
        "                    #We'll just use a tiny bit of the dataset.\n",
        "\n",
        "dataset = load_dataset(\"merve/turkish_instructions\")[\"train\"].select(range(ds_len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWZjTJ4xQobC",
        "outputId": "fe746e1c-b439-4fd3-ea6f-280ef669acc1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Unnamed: 0', 'talimat', ' giriş', ' çıktı'],\n",
              "    num_rows: 1000\n",
              "})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = { \"example\":  [talimat + çıktı for talimat, çıktı in zip(dataset[\"talimat\"], dataset[\" çıktı\"])]} \n",
        "train_dataset = Ds.from_dict(train_dataset)\n",
        "\n",
        "new_dataset = datasets.DatasetDict( {\"train\":train_dataset} )\n",
        "new_dataset = new_dataset[\"train\"]\n",
        "\n",
        "# GPT-2 gets continous text as input, rather than separate instruction-answer pairs. So we concatanate them. Makes training longer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['example'],\n",
              "    num_rows: 1000\n",
              "})"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uS_D-CTPQ1pV"
      },
      "outputs": [],
      "source": [
        "class MyDataSet(Dataset):\n",
        "  def __init__(self, tokenizer, data, block_size):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.data = data\n",
        "    self.block_size = block_size\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    item = self.data[idx]\n",
        "    tokenized_inputs = self.tokenizer(\n",
        "        item[\"example\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=self.block_size,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulG1602XSQPc",
        "outputId": "29d6dd7b-da99-435d-fe65-a0b8b0ef3f39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['__add__', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_is_protocol', 'block_size', 'data', 'tokenizer']\n"
          ]
        }
      ],
      "source": [
        "data = MyDataSet(tokenizer, new_dataset, 512)\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "print(dir(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V04X-PlUSRhM",
        "outputId": "e913281c-f506-45b4-9a8f-8f72978a7fe2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['example'],\n",
            "    num_rows: 1000\n",
            "})\n",
            "GPT2TokenizerFast(name_or_path='./MycosmosGPT', vocab_size=50257, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
            "\t0: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(data.data)\n",
        "print(data.tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1Bbi5HIcS3LY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\yusuf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=10,\n",
        "    learning_rate=5e-5,\n",
        "    logging_steps=100,\n",
        "    output_dir='./results'\n",
        ")\n",
        "\n",
        "trainer= Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=data,\n",
        "    eval_dataset=None,\n",
        "    data_collator=data_collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# These lines are used to monitor and optimize GPU memory usage.\n",
        "\n",
        "#torch.cuda.memory_allocated()\n",
        "\n",
        "#import os\n",
        "\n",
        "#os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "#torch.cuda.empty_cache()\n",
        "\n",
        "#!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "jtt4RPNqU1Qb",
        "outputId": "8806e284-3487-4e5f-cd37-272fdde190a2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd096a510b204d11b72b74d625915971",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d54IFrEyVqaC"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[18486, 23877,  2106,  5677, 29186,   373,   743,   843,   915,  3624,\n",
              "            14]], device='cuda:0')"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt =\"Zor günlere rağmen hayatı sevmek için 5 neden sırala.\"\n",
        "\n",
        "input_ids = tokenizer(prompt, return_tensors =\"pt\").input_ids\n",
        "attention_mask = tokenizer(prompt, return_tensors = \"pt\").attention_mask\n",
        "\n",
        "input_ids = input_ids.to(device)\n",
        "attention_mask = attention_mask.to(device)\n",
        "\n",
        "input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    attention_mask=attention_mask,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        "    max_length=100,\n",
        "    num_beams=5,\n",
        "    temperature=1.5,\n",
        "    top_k=50,\n",
        "    do_sample=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[18486, 23877,  2106,  5677, 29186,   373,   743,   843,   915,  3624,\n",
              "            14,    17,    14,  7191,  3937,   299, 21882,   439,    26,  7191,\n",
              "          3937,   299, 21882,  4106,  5083,    14,   386,    14, 17111,    26,\n",
              "         17111,   373,   307,  2202,    12,   307,  2202,   299,   307,  2202,\n",
              "           483,    14,   609,    14, 37075,   439,    26,   790,  4137,  1910,\n",
              "           307,   838, 22503, 14603,    14,   750,    14, 43812,  3731,    26,\n",
              "           790,  4137,  3628,   307,  1824,  1045,   721,   307,  4552, 14422,\n",
              "          6538, 24994,    14,   743,    14,  7507,  2985,    26,   790,  4137,\n",
              "          3628,   307,  1824,  1045,   721,   307,  4552, 14422, 19025, 24994,\n",
              "            14,   950,    14, 21401,   808,    26,   790,  4137,  3628,   307]],\n",
              "       device='cuda:0')"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zor günlere rağmen hayatı sevmek için 5 neden sırala.1. Tutku ve iyimserlik: Tutku ve iyimserliğin gücü. 2. Başarı: Başarı için bir amaç, bir amaç ve bir amaçtır. 3. Esneklik: Bir sorunu hızlı bir şekilde çözme yeteneği. 4. Yaratıcılık: Bir sorunu belirli bir süre içinde yeni bir bakış açısı kazanma becerisi. 5. Kararlılık: Bir sorunu belirli bir süre içinde yeni bir bakış açısı getirme becerisi. 6. Cesaret: Bir sorunu belirli bir\n"
          ]
        }
      ],
      "source": [
        "text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.save_model(\"SFT-cosmos-gpt2-merve-2k\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('SFT-cosmos-gpt2-merve8k-33p\\\\tokenizer_config.json',\n",
              " 'SFT-cosmos-gpt2-merve8k-33p\\\\special_tokens_map.json',\n",
              " 'SFT-cosmos-gpt2-merve8k-33p\\\\vocab.json',\n",
              " 'SFT-cosmos-gpt2-merve8k-33p\\\\merges.txt',\n",
              " 'SFT-cosmos-gpt2-merve8k-33p\\\\added_tokens.json',\n",
              " 'SFT-cosmos-gpt2-merve8k-33p\\\\tokenizer.json')"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.save_pretrained(\"SFT-cosmos-gpt2-merve-2k\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
